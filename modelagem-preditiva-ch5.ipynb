{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4966d21-aaaa-4b2a-a630-b232079bac5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === 1) (Re)Criar a view 'dados_ml' === \n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW dados_ml AS\n",
    "WITH vendas_mensais AS (\n",
    "    SELECT\n",
    "        dp.product_key,\n",
    "        dp.product_name,\n",
    "        dp.product_category_name,\n",
    "        dp.product_subcategory_name,\n",
    "        fs.customer_key,\n",
    "        dc.territory_id,\n",
    "        fs.territory_name,\n",
    "        fs.country_region_code,\n",
    "        YEAR(fs.order_date) AS ano,\n",
    "        MONTH(fs.order_date) AS mes,\n",
    "        QUARTER(fs.order_date) AS trimestre,\n",
    "        DATE_TRUNC('MONTH', fs.order_date) AS data_referencia,\n",
    "        SUM(fs.order_quantity) AS quantidade_vendida,\n",
    "        SUM(fs.net_amount) AS total_vendas_liquidas\n",
    "    FROM ted_dev.dev_guilherme_sobrinho_marts.fact_sales fs\n",
    "    JOIN ted_dev.dev_guilherme_sobrinho_marts.dim_product dp\n",
    "        ON fs.product_key = dp.product_key\n",
    "    JOIN ted_dev.dev_guilherme_sobrinho_marts.dim_customer dc\n",
    "        ON fs.customer_key = dc.customer_key\n",
    "    GROUP BY\n",
    "        dp.product_key, dp.product_name, dp.product_category_name, dp.product_subcategory_name,\n",
    "        fs.customer_key, dc.territory_id, fs.territory_name, fs.country_region_code,\n",
    "        YEAR(fs.order_date), MONTH(fs.order_date), QUARTER(fs.order_date),\n",
    "        DATE_TRUNC('MONTH', fs.order_date)\n",
    "),\n",
    "com_lags AS (\n",
    "    SELECT\n",
    "        vm.*,\n",
    "        COALESCE(LAG(vm.quantidade_vendida, 1) OVER (PARTITION BY vm.product_key, vm.territory_id ORDER BY vm.data_referencia), 0) AS lag_1,\n",
    "        COALESCE(LAG(vm.quantidade_vendida, 2) OVER (PARTITION BY vm.product_key, vm.territory_id ORDER BY vm.data_referencia), 0) AS lag_2,\n",
    "        COALESCE(LAG(vm.quantidade_vendida, 3) OVER (PARTITION BY vm.product_key, vm.territory_id ORDER BY vm.data_referencia), 0) AS lag_3,\n",
    "        COALESCE(LAG(vm.quantidade_vendida, 12) OVER (PARTITION BY vm.product_key, vm.territory_id ORDER BY vm.data_referencia), 0) AS lag_12\n",
    "    FROM vendas_mensais vm\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    (lag_1 + lag_2 + lag_3) / 3.0 AS media_movel_3m\n",
    "FROM com_lags\n",
    "\"\"\")\n",
    "print(\"View 'dados_ml' (re)criada com sucesso.\")\n",
    "\n",
    "# === 2) Checar se view existe e mostrar amostra ===\n",
    "try:\n",
    "    df_sample = spark.sql(\"SELECT product_key, product_name, territory_id, data_referencia, quantidade_vendida, lag_1, lag_2, lag_3, lag_12, media_movel_3m FROM dados_ml LIMIT 5\")\n",
    "    display(df_sample)\n",
    "    print(\"A view 'dados_ml' está pronta e com amostra exibida acima.\")\n",
    "except Exception as e:\n",
    "    print(\"Erro ao acessar a view 'dados_ml':\", e)\n",
    "    raise\n",
    "\n",
    "# === 3) Contador rápido pra confirmar registros ===\n",
    "count = spark.sql(\"SELECT count(*) AS cnt FROM dados_ml\").collect()[0][\"cnt\"]\n",
    "print(f\"Total de linhas em dados_ml: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0391af72-11d1-4e32-822f-b2fafc85ea5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Checkpoint 5 - Script completo para Databricks (AdventureWorks)\n",
    "\n",
    " - Previsões 3 meses por produto x loja (RF, XGB, LGB + média móvel)\n",
    " - Comparação de modelos de regressão (Linear, RF, GBoost, LightGBM)\n",
    " - Análise de sazonalidade para 1 produto\n",
    " - Crescimento por centro de distribuição (EUA vs Resto do Mundo) (baseline)\n",
    " - Estimativa de zíperes para luvas (2 por par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8251384f-b405-4b27-b844-6e72f45b8f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# descomentar se necessário\n",
    "%pip install xgboost\n",
    "%pip install lightgbm\n",
    "# %pip install prophet   # opcional\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Modelagem / ML\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6070cfbd-35ff-4426-9e1f-d55b41bd37c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 0) Verificar existência da view 'dados_ml'\n",
    "# -------------------------\n",
    "try:\n",
    "    display(spark.sql(\"SELECT * FROM dados_ml LIMIT 3\"))\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"A view 'dados_ml' não existe. Execute seu SQL de preparação antes deste script.\") from e\n",
    "\n",
    "# -------------------------\n",
    "# 1) Preparar DataFrame Spark para forecast granular\n",
    "# -------------------------\n",
    "df_ml_spark = spark.table(\"dados_ml\")\n",
    "\n",
    "df_for_forecast = df_ml_spark.select(\n",
    "    F.col(\"product_name\").alias(\"produto\"),\n",
    "    F.col(\"territory_id\").cast(\"string\").alias(\"id_loja\"),\n",
    "    F.col(\"data_referencia\").alias(\"ano_mes\"),\n",
    "    F.col(\"quantidade_vendida\").alias(\"qtde\"),\n",
    "    F.col(\"media_movel_3m\").alias(\"media_movel_3m\"),\n",
    "    F.col(\"product_category_name\"),\n",
    "    F.col(\"product_subcategory_name\"),\n",
    "    F.col(\"country_region_code\"),\n",
    "    F.col(\"product_key\")\n",
    ")\n",
    "\n",
    "# Filtrar nulos / qtde <= 0\n",
    "df_for_forecast = df_for_forecast.filter(F.col(\"id_loja\").isNotNull() & (F.col(\"qtde\") > 0))\n",
    "df_for_forecast = df_for_forecast.repartition(\"produto\", \"id_loja\")\n",
    "print(\"Registros preparados para forecast (spark):\", df_for_forecast.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80eaa405-ab88-405f-b17f-f317ed2b3134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Função de forecast (applyInPandas)\n",
    "# -------------------------\n",
    "def forecast_3meses_com_metrica(pdf):\n",
    "    produto = pdf['produto'].iloc[0]\n",
    "    id_loja = str(pdf['id_loja'].iloc[0])\n",
    "\n",
    "    pdf = pdf.sort_values('ano_mes').copy()\n",
    "    pdf['ano_mes'] = pd.to_datetime(pdf['ano_mes'])\n",
    "    pdf = pdf.reset_index(drop=True)\n",
    "\n",
    "    # fallback quando poucos dados\n",
    "    if len(pdf) < 6 or pdf['qtde'].sum() == 0:\n",
    "        ma_pred = float(pdf['qtde'].mean() * 3) if len(pdf) > 0 else 0.0\n",
    "        return pd.DataFrame({\n",
    "            'produto': [produto],\n",
    "            'id_loja': [id_loja],\n",
    "            'rf': [ma_pred], 'xgb': [ma_pred], 'lgb': [ma_pred], 'ma': [ma_pred],\n",
    "            'rf_mae': [None], 'rf_rmse': [None], 'rf_r2': [None],\n",
    "            'xgb_mae': [None], 'xgb_rmse': [None], 'xgb_r2': [None],\n",
    "            'lgb_mae': [None], 'lgb_rmse': [None], 'lgb_r2': [None]\n",
    "        })\n",
    "\n",
    "    pdf['ano'] = pdf['ano_mes'].dt.year\n",
    "    pdf['mes'] = pdf['ano_mes'].dt.month\n",
    "    X = pdf[['ano', 'mes']]\n",
    "    y = pdf['qtde'].values\n",
    "\n",
    "    if len(X) <= 3:\n",
    "        ma_pred = float(pdf['qtde'].rolling(3, min_periods=1).mean().iloc[-1] * 3)\n",
    "        return pd.DataFrame({\n",
    "            'produto':[produto],'id_loja':[id_loja],\n",
    "            'rf':[ma_pred], 'xgb':[ma_pred], 'lgb':[ma_pred], 'ma':[ma_pred],\n",
    "            'rf_mae':[None],'rf_rmse':[None],'rf_r2':[None],\n",
    "            'xgb_mae':[None],'xgb_rmse':[None],'xgb_r2':[None],\n",
    "            'lgb_mae':[None],'lgb_rmse':[None],'lgb_r2':[None]\n",
    "        })\n",
    "\n",
    "    X_train, X_test = X[:-3].values, X[-3:].values\n",
    "    y_train, y_test = y[:-3], y[-3:]\n",
    "\n",
    "    # Modelos (valores de n_estimators ajustáveis)\n",
    "    rf_model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    xgb_model = XGBRegressor(n_estimators=50, n_jobs=1, random_state=42, verbosity=0)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    lgb_model = LGBMRegressor(n_estimators=50, n_jobs=1, random_state=42, verbose=-1)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    rf_test_pred = rf_model.predict(X_test)\n",
    "    xgb_test_pred = xgb_model.predict(X_test)\n",
    "    lgb_test_pred = lgb_model.predict(X_test)\n",
    "\n",
    "    # Métricas com try/except (segurança)\n",
    "    try:\n",
    "        rf_mae = float(mean_absolute_error(y_test, rf_test_pred))\n",
    "        rf_rmse = float(mean_squared_error(y_test, rf_test_pred, squared=False))\n",
    "        rf_r2 = float(r2_score(y_test, rf_test_pred))\n",
    "    except:\n",
    "        rf_mae = rf_rmse = rf_r2 = None\n",
    "\n",
    "    try:\n",
    "        xgb_mae = float(mean_absolute_error(y_test, xgb_test_pred))\n",
    "        xgb_rmse = float(mean_squared_error(y_test, xgb_test_pred, squared=False))\n",
    "        xgb_r2 = float(r2_score(y_test, xgb_test_pred))\n",
    "    except:\n",
    "        xgb_mae = xgb_rmse = xgb_r2 = None\n",
    "\n",
    "    try:\n",
    "        lgb_mae = float(mean_absolute_error(y_test, lgb_test_pred))\n",
    "        lgb_rmse = float(mean_squared_error(y_test, lgb_test_pred, squared=False))\n",
    "        lgb_r2 = float(r2_score(y_test, lgb_test_pred))\n",
    "    except:\n",
    "        lgb_mae = lgb_rmse = lgb_r2 = None\n",
    "\n",
    "    # Prever próximos 3 meses\n",
    "    last_date = pdf['ano_mes'].max()\n",
    "    future_dates = pd.date_range(start=last_date + pd.offsets.MonthBegin(1), periods=3, freq='MS')\n",
    "    future_df = pd.DataFrame({'ano': future_dates.year, 'mes': future_dates.month})\n",
    "\n",
    "    try:\n",
    "        rf_pred = float(np.clip(rf_model.predict(future_df[['ano','mes']]), 0, None).sum())\n",
    "    except:\n",
    "        rf_pred = float('nan')\n",
    "    try:\n",
    "        xgb_pred = float(np.clip(xgb_model.predict(future_df[['ano','mes']]), 0, None).sum())\n",
    "    except:\n",
    "        xgb_pred = float('nan')\n",
    "    try:\n",
    "        lgb_pred = float(np.clip(lgb_model.predict(future_df[['ano','mes']]), 0, None).sum())\n",
    "    except:\n",
    "        lgb_pred = float('nan')\n",
    "\n",
    "    ma_pred = float(pdf['qtde'].rolling(3, min_periods=1).mean().iloc[-1] * 3)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'produto':[produto],\n",
    "        'id_loja':[id_loja],\n",
    "        'rf':[rf_pred], 'xgb':[xgb_pred], 'lgb':[lgb_pred], 'ma':[ma_pred],\n",
    "        'rf_mae':[rf_mae], 'rf_rmse':[rf_rmse], 'rf_r2':[rf_r2],\n",
    "        'xgb_mae':[xgb_mae], 'xgb_rmse':[xgb_rmse], 'xgb_r2':[xgb_r2],\n",
    "        'lgb_mae':[lgb_mae], 'lgb_rmse':[lgb_rmse], 'lgb_r2':[lgb_r2]\n",
    "    })\n",
    "\n",
    "# Schema resultado\n",
    "schema = StructType([\n",
    "    StructField(\"produto\", StringType()),\n",
    "    StructField(\"id_loja\", StringType()),\n",
    "    StructField(\"rf\", DoubleType()),\n",
    "    StructField(\"xgb\", DoubleType()),\n",
    "    StructField(\"lgb\", DoubleType()),\n",
    "    StructField(\"ma\", DoubleType()),\n",
    "    StructField(\"rf_mae\", DoubleType()),\n",
    "    StructField(\"rf_rmse\", DoubleType()),\n",
    "    StructField(\"rf_r2\", DoubleType()),\n",
    "    StructField(\"xgb_mae\", DoubleType()),\n",
    "    StructField(\"xgb_rmse\", DoubleType()),\n",
    "    StructField(\"xgb_r2\", DoubleType()),\n",
    "    StructField(\"lgb_mae\", DoubleType()),\n",
    "    StructField(\"lgb_rmse\", DoubleType()),\n",
    "    StructField(\"lgb_r2\", DoubleType())\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# 3) Aplicar applyInPandas (forecast por produto x loja)\n",
    "# -------------------------\n",
    "print(\"Iniciando applyInPandas para gerar previsões por produto x loja...\")\n",
    "df_forecast = df_for_forecast.groupBy(\"produto\", \"id_loja\").applyInPandas(\n",
    "    forecast_3meses_com_metrica,\n",
    "    schema=schema\n",
    ")\n",
    "print(\"Forecast gerado. Exibindo amostra:\")\n",
    "display(df_forecast.limit(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c8ed07-7e1d-4f89-b959-9d2afd84a257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Converter view 'dados_ml' para Pandas (modelagem/regressão)\n",
    "# -------------------------\n",
    "print(\"Convertendo view 'dados_ml' para Pandas (para modelagem/regressão)...\")\n",
    "dados_ml_pd = spark.table(\"dados_ml\").toPandas()\n",
    "print(\"Registros em pandas:\", len(dados_ml_pd))\n",
    "\n",
    "if 'data_referencia' not in dados_ml_pd.columns:\n",
    "    raise RuntimeError(\"Coluna 'data_referencia' não encontrada no dataframe pandas.\")\n",
    "\n",
    "dados_ml_pd['data_referencia'] = pd.to_datetime(dados_ml_pd['data_referencia'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b5fb42-831a-4134-9baa-17de835d6f75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 5) Análise de sazonalidade (produto exemplo)\n",
    "# -------------------------\n",
    "product_escolhido = None\n",
    "if product_escolhido is None:\n",
    "    top_prod = dados_ml_pd.groupby('product_name')['quantidade_vendida'].sum().sort_values(ascending=False).head(1)\n",
    "    if len(top_prod) == 0:\n",
    "        raise RuntimeError(\"Não há dados suficientes para análise de sazonalidade.\")\n",
    "    product_escolhido = top_prod.index[0]\n",
    "\n",
    "print(f\"Analisando sazonalidade para o produto: {product_escolhido}\")\n",
    "\n",
    "df_prod_saz = dados_ml_pd[dados_ml_pd['product_name'] == product_escolhido].copy()\n",
    "df_prod_saz = df_prod_saz.groupby(df_prod_saz['data_referencia'].dt.to_period('M'))['quantidade_vendida'].sum().reset_index()\n",
    "df_prod_saz['ano_mes'] = df_prod_saz['data_referencia'].dt.to_timestamp()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.lineplot(data=df_prod_saz, x='ano_mes', y='quantidade_vendida', marker=\"o\")\n",
    "plt.title(f\"Sazonalidade: vendas mensais para '{product_escolhido}'\")\n",
    "plt.xlabel(\"Mês\")\n",
    "plt.ylabel(\"Quantidade vendida\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8960524b-3d76-42ab-8a29-c82dd8af6714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 6) Comparação de Modelos de Regressão\n",
    "# -------------------------\n",
    "print(\"\\nComparando modelos de regressão usando features: lags + time + categorias\")\n",
    "\n",
    "# Garantir colunas de lag existem\n",
    "for lag in ['lag_1', 'lag_2', 'lag_3', 'lag_12']:\n",
    "    if lag not in dados_ml_pd.columns:\n",
    "        dados_ml_pd[lag] = 0\n",
    "    else:\n",
    "        dados_ml_pd[lag] = dados_ml_pd[lag].fillna(0)\n",
    "\n",
    "# Garantir período\n",
    "dados_ml_pd['mes'] = dados_ml_pd['data_referencia'].dt.month\n",
    "dados_ml_pd['trimestre'] = dados_ml_pd['data_referencia'].dt.quarter\n",
    "\n",
    "features = ['lag_1', 'lag_2', 'lag_3', 'lag_12', 'mes', 'trimestre', 'product_category_name', 'product_subcategory_name']\n",
    "target = 'quantidade_vendida'\n",
    "df_features = dados_ml_pd[dados_ml_pd[target].notnull()].copy()\n",
    "\n",
    "max_date = df_features['data_referencia'].max()\n",
    "corte = max_date - pd.DateOffset(months=3)\n",
    "train_df = df_features[df_features['data_referencia'] <= corte].copy()\n",
    "test_df = df_features[df_features['data_referencia'] > corte].copy()\n",
    "print(f\"Treino: {train_df.shape[0]} linhas, Teste: {test_df.shape[0]} linhas\")\n",
    "\n",
    "X_train = train_df[features].copy()\n",
    "y_train = train_df[target].values\n",
    "X_test = test_df[features].copy()\n",
    "y_test = test_df[target].values\n",
    "\n",
    "categorical_features = ['product_category_name', 'product_subcategory_name']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        pipe = Pipeline([(\"pre\", preprocessor), (\"model\", model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        preds = pipe.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        mape = mean_absolute_percentage_error(y_test, preds)\n",
    "        results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape}\n",
    "    except Exception as e:\n",
    "        results[name] = {\"MAE\": None, \"RMSE\": None, \"MAPE\": None}\n",
    "        print(f\"Erro treinando {name}: {e}\")\n",
    "\n",
    "print(\"\\nMétricas de comparação dos modelos (test set):\")\n",
    "for name, mets in results.items():\n",
    "    mae = f\"{mets['MAE']:.2f}\" if mets['MAE'] is not None else \"NA\"\n",
    "    rmse = f\"{mets['RMSE']:.2f}\" if mets['RMSE'] is not None else \"NA\"\n",
    "    mape = f\"{mets['MAPE']:.2f}\" if mets['MAPE'] is not None else \"NA\"\n",
    "    print(f\"- {name}: MAE={mae} | RMSE={rmse} | MAPE={mape}\")\n",
    "\n",
    "valid_results = {k:v for k,v in results.items() if v['RMSE'] is not None}\n",
    "if valid_results:\n",
    "    best = min(valid_results.items(), key=lambda x: x[1]['RMSE'])\n",
    "    print(f\"\\nMelhor modelo (menor RMSE): {best[0]} (RMSE={best[1]['RMSE']:.2f})\")\n",
    "else:\n",
    "    print(\"\\nNão foi possível determinar o melhor modelo (faltam métricas).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cf226c6-3e03-4520-bec1-b4246213aa48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 7) Crescimento por Centro de Distribuição (baseline média móvel)\n",
    "# -------------------------\n",
    "\n",
    "print(\"\\nAnalisando crescimento por centro de distribuição (EUA vs Resto do Mundo) usando baseline média móvel\")\n",
    "\n",
    "df_pred_baseline = df_ml_spark.select(\n",
    "    F.col(\"product_key\"),\n",
    "    F.col(\"product_name\"),\n",
    "    F.col(\"territory_id\"),\n",
    "    F.col(\"country_region_code\"),\n",
    "    F.col(\"media_movel_3m\").cast(\"double\").alias(\"media_movel_3m\")\n",
    ").toPandas()\n",
    "\n",
    "df_pred_baseline['media_movel_3m'] = df_pred_baseline['media_movel_3m'].fillna(0.0)\n",
    "df_pred_baseline['previsao_3m_baseline'] = df_pred_baseline['media_movel_3m'] * 3.0\n",
    "\n",
    "df_pred_baseline['territorio_grupo'] = df_pred_baseline['country_region_code'].apply(lambda x: 'EUA' if str(x).upper() == 'US' else 'Resto do Mundo')\n",
    "\n",
    "crescimento = df_pred_baseline.groupby('territorio_grupo')['previsao_3m_baseline'].sum().reset_index()\n",
    "print(\"\\nPrevisão (baseline média móvel) - Próximos 3 meses por grupo de territórios:\")\n",
    "display(crescimento)\n",
    "\n",
    "if crescimento.loc[crescimento['previsao_3m_baseline'].idxmax(),'territorio_grupo'] == 'EUA':\n",
    "    print(\"👉 O grupo com maior crescimento previsto é: EUA\")\n",
    "else:\n",
    "    print(\"👉 O grupo com maior crescimento previsto é: Resto do Mundo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d5e78d-3591-4719-8559-1ec7032ee294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 8) Estimativa de zíperes para luvas (2 por par)\n",
    "# -------------------------\n",
    "print(\"\\nEstimando zíperes necessários para luvas (2 por par) usando baseline média móvel\")\n",
    "\n",
    "# Pegar info de categoria/subcategoria para cada product_key\n",
    "prod_info = df_ml_spark.select(\"product_key\",\"product_name\",\"product_category_name\",\"product_subcategory_name\").distinct().toPandas()\n",
    "df_luvas = df_pred_baseline.merge(prod_info, on=\"product_key\", how=\"left\")\n",
    "\n",
    "if 'product_category_name' in df_luvas.columns and 'product_subcategory_name' in df_luvas.columns:\n",
    "    df_luvas_filtered = df_luvas[\n",
    "        (df_luvas['product_category_name'].str.lower() == 'clothing') &\n",
    "        (df_luvas['product_subcategory_name'].str.lower() == 'gloves')\n",
    "    ]\n",
    "else:\n",
    "    df_luvas_filtered = df_luvas[df_luvas['product_name'].str.contains('glove|gloves', case=False, na=False)]\n",
    "\n",
    "total_luvas_prev = df_luvas_filtered['previsao_3m_baseline'].sum()\n",
    "zippers_needed = int(np.round(total_luvas_prev * 2))\n",
    "\n",
    "print(f\"Previsão total de pares de luvas (próx 3 meses, baseline): {total_luvas_prev:.2f}\")\n",
    "print(f\"Estimativa de zíperes necessária (2 por par): {zippers_needed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340b97b4-9893-435a-8af8-91e172104480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 9) Outputs / Salvamentos finais (opcionais)\n",
    "# -------------------------\n",
    "print(\"\\nExemplos de saída e salvamento (comente/descomente conforme desejar):\")\n",
    "display(df_forecast.orderBy(F.desc(\"ma\")).limit(20))\n",
    "\n",
    "# Exemplos de escrita\n",
    "# df_forecast.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dev_guilherme.forecast_produto_loja_3m\")\n",
    "# df_pred_baseline[['product_key','product_name','territory_id','country_region_code','previsao_3m_baseline']].to_csv(\"/dbfs/tmp/previsao_baseline_3m.csv\", index=False)\n",
    "\n",
    "print(\"\\nScript finalizado com sucesso.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "modelagem-preditiva-ch5",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
